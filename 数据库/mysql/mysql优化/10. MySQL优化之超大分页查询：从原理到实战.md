## 一、引言

在实际的项目开发中，我们经常会遇到需要处理大量数据的分页查询场景。当数据量达到数百万甚至上亿时，传统的分页查询方法往往会变得非常缓慢，甚至导致系统崩溃。本文将详细介绍如何优化MySQL中的超大分页查询，从原理到实战，帮助大家提升查询性能，解决实际问题。

**tips:**

后续还会不断更新，辛苦喜欢的朋友**点赞关注**，一起学习一起进步！

## 二、背景

### 2.1 传统分页查询的痛点

在MySQL中，我们通常使用`LIMIT`和`[OFFSET](https://zhida.zhihu.com/search?content_id=254205927&content_type=Article&match_order=1&q=OFFSET&zhida_source=entity)`来实现分页查询。例如：

```mysql
SELECT * FROM table_name LIMIT 1000000, 10;
```

这条SQL语句的含义是从第1000001行开始，取10行数据。然而，当`OFFSET`值非常大时，这种查询方式会变得非常慢。原因如下：

1. **全表扫描**：MySQL需要扫描前1000000行数据，然后丢弃它们，再取后面的10行数据。
2. **内存消耗**：在扫描过程中，MySQL会将大量数据加载到内存中，导致内存消耗巨大。
3. **锁竞争**：在高并发场景下，大量的分页查询会导致表锁竞争，进一步降低性能

### 2.2 优化的必要性

随着数据量的不断增长，传统的分页查询方法已经无法满足业务需求。优化超大分页查询不仅可以提升查询性能，还可以减少系统资源的消耗，提高系统的稳定性和可靠性。

导致的现象是：

1. 用户点击“第100页”时页面卡死
2. 后台管理导出数据时内存溢出
3. 接口响应时间从1秒飙升到20秒+

### **2.3 不同数据量下的性能拐点**

![](https://pic1.zhimg.com/v2-0e9361e779764cdd04c4bd3b99b3c936_1440w.jpg)

## 三、优化的方案：**四层防御体系**

### **3.1 第一层：[索引覆盖](https://zhida.zhihu.com/search?content_id=254205927&content_type=Article&match_order=1&q=%E7%B4%A2%E5%BC%95%E8%A6%86%E7%9B%96&zhida_source=entity) + [延迟关联](https://zhida.zhihu.com/search?content_id=254205927&content_type=Article&match_order=1&q=%E5%BB%B6%E8%BF%9F%E5%85%B3%E8%81%94&zhida_source=entity)（适用中等数据量）**

**1. 原理剖析**

- **问题根源**：原始 `LIMIT offset, size` 需要扫描 `offset + size` 行数据，再丢弃前 `offset` 行。
- **优化思路**：

- **子查询仅查主键**：利用覆盖索引（Covering Index）避免回表（减少磁盘IO）。
- **外层精准定位**：通过主键快速获取完整数据（主键索引直接定位磁盘位置）。

```sql
-- 原始写法  
SELECT * FROM user_order  
ORDER BY create_time DESC  
LIMIT 1000000, 10;  

-- 优化写法  
SELECT * FROM user_order  
INNER JOIN (  
    SELECT id FROM user_order  
    ORDER BY create_time DESC  
    LIMIT 1000000, 10  
) AS tmp USING(id);  
```

**2. 执行流程对比**

```text
graph TD  
    A[原始查询] --> B[全表扫描]  
    B --> C[排序所有数据]  
    C --> D[丢弃前offset行]  
    D --> E[返回size行]  

    F[优化查询] --> G[子查询只查主键]  
    G --> H[覆盖索引快速扫描]  
    H --> I[丢弃前offset行主键]  
    I --> J[外层通过主键取数据] 
```

**3. 关键指标**

|数据量|原方案耗时|优化后耗时|扫描行数下降比例|
|---|---|---|---|
|500万|6.5秒|1.2秒|70%↓（500万→150万）|
|1000万|13秒|2.8秒|75%↓（1000万→250万）|

**4. 适用场景**

- **中等数据量**（单表百万级）
- **排序字段有索引**（如`create_time`需建立联合索引）

### **3.2 第二层：[游标分页法](https://zhida.zhihu.com/search?content_id=254205927&content_type=Article&match_order=1&q=%E6%B8%B8%E6%A0%87%E5%88%86%E9%A1%B5%E6%B3%95&zhida_source=entity)（适用深度分页）**

**1. 原理剖析**

- **问题根源**：`OFFSET`导致扫描无关数据，时间复杂度为O(N)。
- **优化思路**：

- **记录游标**：记住上一页最后一条数据的排序字段值（如`create_time`和`id`）。
- **条件过滤**：下页查询直接跳过已读数据（类似链表遍历）。

**2. 执行流程对比**

```sql
-- 第一页  
SELECT * FROM user_order  
ORDER BY create_time DESC, id DESC  
LIMIT 10;  

-- 后续分页（传入上一页最后一条记录的create_time和id）  
SELECT * FROM user_order  
WHERE create_time <= '2023-06-01 12:00:00' AND id < 100  
ORDER BY create_time DESC, id DESC  
LIMIT 10;  
```

**3. 关键指标**

|数据量|原方案耗时|优化后耗时|扫描行数|
|---|---|---|---|
|500万|6.5秒|25ms|1000010 → 10|
|1000万|13秒|28ms|10000010 → 10|

**4. 适用场景**

- **深度分页**（用户持续翻页，如无限滚动）
- **排序字段唯一且有序**（需`ORDER BY time, id`避免重复）

### 3.3 **第三层：[异步缓存](https://zhida.zhihu.com/search?content_id=254205927&content_type=Article&match_order=1&q=%E5%BC%82%E6%AD%A5%E7%BC%93%E5%AD%98&zhida_source=entity) + [预加载](https://zhida.zhihu.com/search?content_id=254205927&content_type=Article&match_order=1&q=%E9%A2%84%E5%8A%A0%E8%BD%BD&zhida_source=entity)（高并发场景）**

**1. 原理剖析**

- **问题根源**：高并发下重复计算相同分页数据，浪费CPU和IO。
- **优化思路**：

- **预生成分页**：后台异步计算热门分页数据并缓存（如用户常访问的前100页）。
- **缓存淘汰策略**：LRU算法保留最近访问的分页，释放不活跃数据内存。

**2. 架构设计**

```text
graph LR  
    User1 -->|请求第5页| Cache  
    User2 -->|请求第5页| Cache  
    Cache -->|命中| Response  
    Cache -->|未命中| DB[(MySQL)]  
    DB -->|查询并缓存| Cache  
    Scheduler[定时任务] -->|预加载热门页| Cache  
```

**3. 关键指标**

|并发量|原方案QPS|优化后QPS|缓存命中率|
|---|---|---|---|
|100|12|220|92%|
|500|8|180|85%|

**4. 适用场景**

- **读多写少**（如新闻、商品列表）
- **数据变更频率低**（缓存有效期可设置较长）

### **3.4 [Elasticsearch](https://zhida.zhihu.com/search?content_id=254205927&content_type=Article&match_order=1&q=Elasticsearch&zhida_source=entity)辅助查询**

**1. 原理剖析**

- **问题根源**：MySQL不适合海量数据复杂排序和过滤。
- **优化思路**：

- **写双写**：数据同时写入MySQL和ES（最终一致性）。
- **读走ES**：利用ES的倒排索引和分片机制加速查询。

**2. ES分页方案对比**

|方案|原理|优点|缺点|
|---|---|---|---|
|from/size|类似MySQL LIMIT|简单易用|深度分页性能差|
|scroll|生成快照遍历|适合大数据导出|占用内存、非实时|
|search_after|类似游标分页|高性能、实时|必须连续翻页|

**3. 关键指标**

|数据量|MySQL分页耗时|ES search_after耗时|
|---|---|---|
|5000万|65秒|230ms|
|1亿|130秒+|260ms|

**4. 适用场景**

- **超大数据量**（亿级以上）
- **复杂查询**（多字段过滤、排序、聚合）

## **四**、**代码实战：从青铜到王者的分页改造**

以下基于电商、社交、物流等真实场景，展示不同优化层级的代码实现及效果对比：

### **4.1 电商订单列表优化（延迟关联 + 覆盖索引）**

**场景**：用户中心需展示近3年订单，默认按下单时间倒序，数据量2000万+，翻页至100页后响应超时。

**1. 原始代码（青铜段位）**

```text
public Page<Order> listOrders(int page, int size) {  
    String sql = "SELECT * FROM orders WHERE user_id = ? ORDER BY create_time DESC LIMIT ?, ?";  
    return jdbcTemplate.query(sql, new OrderRowMapper(), userId, (page-1)*size, size);  
}  
```

**问题**：当`page=1000`（`LIMIT 100000, 20`），执行时间12秒，扫描100020行。

**2. 优化代码（黄金段位）**

```java
-- 创建覆盖索引  
ALTER TABLE orders ADD INDEX idx_user_create (user_id, create_time, id);  

-- Java代码改造  
public Page<Order> listOrdersOpt(Long userId, int page, int size) {  
    String subQuery = "SELECT id FROM orders WHERE user_id = ? ORDER BY create_time DESC LIMIT ?, ?";  
    List<Long> orderIds = jdbcTemplate.queryForList(subQuery, Long.class, userId, (page-1)*size, size);  

    if (orderIds.isEmpty()) return Page.empty();  

    String mainQuery = "SELECT * FROM orders WHERE id IN (" + StringUtils.join(orderIds, ",") + ") ORDER BY create_time DESC";  
    return jdbcTemplate.query(mainQuery, new OrderRowMapper());  
}  
```

**优化效果**：

- 扫描行数：100020 → 20（索引覆盖）
- 执行时间：12秒 → 0.8秒

### **4.2 社交APP动态流优化（游标分页法）**

**场景**：用户动态流需支持无限下拉，数据量5亿+，要求第N页响应时间≤50ms。

**1. 原始方案（错误示例）**

```java
// 前端传递page参数  
public List<Post> getFeeds(int page, int size) {  
    String sql = "SELECT * FROM posts WHERE user_id IN (关注列表) ORDER BY post_time DESC LIMIT ?, ?";  
    return jdbcTemplate.query(sql, new PostMapper(), (page-1)*size, size);  
}  
```

**问题**：当用户翻到第500页，接口超时（MySQL CPU飙升）。

**2. 游标分页改造（王者段位）**

```java
// 前端传递lastPostId和lastPostTime  
public List<Post> getFeedsOpt(Long lastPostId, LocalDateTime lastPostTime, int size) {  
    String sql = "SELECT * FROM posts " +  
                 "WHERE post_time < ? OR (post_time = ? AND id < ?) " +  
                 "AND user_id IN (关注列表) " +  
                 "ORDER BY post_time DESC, id DESC LIMIT ?";  
    return jdbcTemplate.query(sql, new PostMapper(),   
        lastPostTime, lastPostTime, lastPostId, size);  
}  
```

**优化效果**：

- 扫描行数：线性增长 → 固定扫描size行
- 执行时间：2秒 → 23ms（数据量5亿）

### **4.3 物流轨迹查询优化（异步缓存 + 预加载）**

**场景**：物流公司后台需分页导出10万条轨迹数据，频繁OOM。

**1. 原始方案（内存分页）**

```java
public List<LogisticTrack> exportTracks() {  
    List<LogisticTrack> all = jdbcTemplate.query("SELECT * FROM tracks", new TrackMapper()); // 加载100万数据到内存  
    return partitionList(all, 10000); // 内存分页  
}  
```

**问题**：导出时堆内存溢出（GC overhead）。

**2. 分页缓存改造（钻石段位）**

```java
// 使用Spring Batch分页读取  
@Bean  
public JdbcPagingItemReader<LogisticTrack> trackReader() {  
    Map<String, Object> params = new HashMap<>();  
    params.put("status", "COMPLETED");  

    return new JdbcPagingItemReaderBuilder<LogisticTrack>()  
        .dataSource(dataSource)  
        .fetchSize(5000)  
        .rowMapper(new TrackMapper())  
        .queryProvider(new SqlPagingQueryProviderFactoryBean() {{  
            setSelectClause("*");  
            setFromClause("tracks");  
            setWhereClause("status = :status");  
            setSortKey("create_time");  
        }}.getObject())  
        .parameterValues(params)  
        .build();  
}  

// 分片导出到CSV  
@Bean  
public Step exportStep() {  
    return stepBuilderFactory.get("exportStep")  
        .<LogisticTrack, LogisticTrack>chunk(1000)  
        .reader(trackReader())  
        .writer(csvWriter())  
        .build();  
}  
```

**优化效果**：

- 内存占用：2GB → 50MB
- 导出时间：15分钟 → 3分钟

### **4.4 电商商品搜索优化（ES终极方案）**

**场景**：商品搜索页支持按价格、销量、评分等多维度分页，数据量3亿+。

**1. MySQL方案（灾难现场）**

```sql
SELECT * FROM products  
WHERE price BETWEEN 100 AND 500  
  AND category = 'electronics'  
ORDER BY sales DESC  
LIMIT 1000000, 20; -- 执行时间: 28秒  
```

**2. ES + search_after方案（荣耀王者）**

```text
// 首次查询  
SearchRequest request = new SearchRequest("products");  
SearchSourceBuilder sourceBuilder = new SearchSourceBuilder()  
    .query(QueryBuilders.boolQuery()  
        .filter(QueryBuilders.rangeQuery("price").gte(100).lte(500))  
        .filter(QueryBuilders.termQuery("category", "electronics"))  
    )  
    .sort("sales", SortOrder.DESC)  
    .size(20);  

SearchResponse response = client.search(request, RequestOptions.DEFAULT);  

// 后续分页（使用search_after）  
Object[] lastSortValues = response.getHits().getHits()[19].getSortValues();  
sourceBuilder.searchAfter(lastSortValues);  
```

**优化效果**：

- 响应时间：28秒 → 210ms
- 资源消耗：MySQL CPU 90% → ES集群负载均衡

## **五**、**总结和展望**

**1. 方案选型决策树**

```text
graph TD       
A[需要跳页?] -->|是| B{数据量级}       
B -->|小于500万| C[索引覆盖+延迟关联]       
B -->|大于500万| D[ES辅助查询]       
A -->|否| E[游标分页法] 
```

**2. 终极效果对比**

![](https://pic1.zhimg.com/v2-1bc249e3b82db251654d075f9f175792_1440w.jpg)

**3. 未来趋势**

- **云数据库优化**：阿里云[PolarDB](https://zhida.zhihu.com/search?content_id=254205927&content_type=Article&match_order=1&q=PolarDB&zhida_source=entity)、AWS [Aurora](https://zhida.zhihu.com/search?content_id=254205927&content_type=Article&match_order=1&q=Aurora&zhida_source=entity)已支持自动分页优化
- **硬件加速**：GPU/FPGA加速排序和过滤操作
- **AI预测分页**：根据用户行为预加载下一页数据

**4. 面试高频问题**

- **问题**：  
    “如何优化MySQL的深分页查询？”
- **回答结构**：

1. 先说现象和原理（OFFSET的代价）
2. 分层给出解决方案（从SQL优化到架构升级）
3. 结合业务场景选型（是否需要跳页、实时性要求）